# LSTM
正確にはRNNとLSTM

## BPTT
時系列モデルではその時間の出力層だけでなく未来の隠れ層からも誤差を受け取る

## 気をつけること
- 直交行列を用いた重み初期化(np.linalg.svd()で求められる)
- ReLUを用いると発散する。シグモイドかtanh
- 勾配消失と同様にLSTMも時間をまたぎ続けると勾配がなくなりやすい

## モデルの構築
### keras
- 全結合の中間層を持つRNN```SimpleRNN(ユニット数, activation=活性化関数, ...)```

### tf


### pytorch

